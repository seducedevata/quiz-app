#!/usr/bin/env python3
"""
Next.js Bridge Server - Connects Next.js frontend to existing Python backend
"""

import sys
import os
import json
import asyncio
import logging
from pathlib import Path
from typing import Dict, Any, Optional
from flask import Flask, request, jsonify
from flask_cors import CORS
from flask_socketio import SocketIO, emit
import threading
import time

# Add the main project directory to Python path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# Try to import your existing Knowledge App modules
mcq_manager_class = None
question_history_class = None
ollama_inference_class = None

try:
    from src.knowledge_app.core.mcq_manager import MCQManager
    mcq_manager_class = MCQManager
    print("‚úÖ MCQManager imported successfully")
except ImportError as e:
    print(f"‚ö†Ô∏è MCQManager import failed: {e}")

try:
    from src.knowledge_app.core.question_history_storage import QuestionHistoryStorage
    question_history_class = QuestionHistoryStorage
    print("‚úÖ QuestionHistoryStorage imported successfully")
except ImportError as e:
    print(f"‚ö†Ô∏è QuestionHistoryStorage import failed: {e}")

try:
    from src.knowledge_app.core.ollama_model_inference import OllamaModelInference
    ollama_inference_class = OllamaModelInference
    print("‚úÖ OllamaModelInference imported successfully")
except ImportError as e:
    print(f"‚ö†Ô∏è OllamaModelInference import failed: {e}")

print("üöÄ Bridge server starting with available modules...")

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
CORS(app, origins=["http://localhost:3000", "http://localhost:3001"])
socketio = SocketIO(app, cors_allowed_origins=["http://localhost:3000", "http://localhost:3001"])

# Initialize your existing components
mcq_manager = None
question_history = None
ollama_inference = None

def initialize_backend():
    """Initialize the existing Python backend components"""
    global mcq_manager, question_history, ollama_inference
    
    try:
        logger.info("üöÄ Initializing backend components...")
        
        # Initialize MCQ Manager if available
        if mcq_manager_class:
            try:
                mcq_manager = mcq_manager_class()
                logger.info("‚úÖ MCQ Manager initialized")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è MCQ Manager initialization failed: {e}")
        
        # Initialize Question History Storage if available
        if question_history_class:
            try:
                question_history = question_history_class()
                logger.info("‚úÖ Question History Storage initialized")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Question History Storage initialization failed: {e}")
        
        # Initialize Ollama Model Inference if available
        if ollama_inference_class:
            try:
                ollama_inference = ollama_inference_class()
                logger.info("‚úÖ Ollama Model Inference initialized")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Ollama Model Inference initialization failed: {e}")
        
        logger.info("üéâ Backend initialization complete!")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Backend initialization failed: {e}")
        return False

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'message': 'Next.js Bridge Server is running',
        'backend_initialized': mcq_manager is not None
    })

@app.route('/api/call', methods=['POST'])
def call_python_method():
    """Main API endpoint for calling Python methods"""
    try:
        data = request.get_json()
        method = data.get('method')
        args = data.get('args', [])
        request_id = data.get('id')
        
        logger.info(f"üìû API Call: {method} with args: {args}")
        
        # Normalize/alias common method names used by the Next.js UI
        method_aliases = {
            # snake_case <-> camelCase equivalents
            'get_available_models': 'getAvailableModels',
            'get_training_history': 'getTrainingHistory',
            'get_training_configuration': 'getTrainingConfiguration',
            'save_training_configuration': 'saveTrainingConfiguration',
            'get_uploaded_files': 'getUploadedFiles',
            'upload_file': 'uploadFile',
            'delete_uploaded_file': 'deleteUploadedFile',
            # settings synonyms
            'save_settings': 'update_settings',
            'save_app_settings': 'update_settings',
            'save_model_preferences': 'update_settings',
            'save_user_preferences': 'update_settings',
            'get_app_settings': 'get_settings',
            'get_advanced_settings': 'get_settings',
            'save_api_keys': 'update_settings',
            'save_advanced_settings': 'update_settings',
        }
        if method in method_aliases:
            logger.info(f"üîÅ Mapping method alias '{method}' -> '{method_aliases[method]}'")
            method = method_aliases[method]

        # Route method calls to appropriate handlers
        result = None

        if method == 'generate_mcq_quiz':
            result = handle_generate_quiz(args[0] if args else {})
        elif method == 'get_question_history':
            result = handle_get_question_history(args[0] if args else {})
        elif method == 'submit_answer':
            result = handle_submit_answer(args[0] if len(args) > 0 else '', args[1] if len(args) > 1 else '')
        elif method == 'get_settings':
            result = handle_get_settings()
        elif method == 'update_settings':
            result = handle_update_settings(args[0] if args else {})
        elif method == 'test_connection':
            result = {'status': 'connected', 'message': 'Bridge is working!'}
        elif method == 'getDeepSeekStatus':
            result = handle_get_deepseek_status()
        elif method == 'start_training':
            result = handle_start_training(args[0] if args else {})
        elif method == 'get_status':
            result = handle_get_status()
        elif method == 'getUploadedFiles':
            result = handle_get_uploaded_files()
        elif method == 'uploadFile':
            result = handle_upload_file_base64(args[0] if len(args) > 0 else 'file', args[1] if len(args) > 1 else '')
        elif method == 'deleteUploadedFile':
            result = handle_delete_uploaded_file(args[0] if args else '')
        elif method == 'getTrainingConfiguration':
            result = handle_get_training_config()
        elif method == 'saveTrainingConfiguration':
            result = handle_save_training_config(args[0] if args else {})
        elif method == 'getAvailableModels':
            result = handle_get_available_models()
        elif method == 'getTrainingHistory':
            result = handle_get_training_history()
        elif method == 'stopTraining':
            result = handle_stop_training()
        elif method == 'get_expert_metrics':
            # Basic stub to keep UI functional
            result = {
                'performance': {
                    'avgThinkingTime': {'value': 1.2, 'trend': 'stable', 'change': 0, 'history': [1.2, 1.3, 1.1]},
                    'avgResponseTime': {'value': 250, 'trend': 'down', 'change': -5, 'history': [300, 270, 250]},
                    'successRate': {'value': 0.95, 'trend': 'up', 'change': 0.02, 'history': [0.9, 0.93, 0.95]},
                    'throughput': {'value': 10, 'trend': 'up', 'change': 1, 'history': [8, 9, 10]},
                },
                'quality': {
                    'complexityScore': {'value': 0.7, 'trend': 'stable', 'change': 0, 'history': [0.68, 0.7, 0.7]},
                    'researchDepth': {'value': 0.6, 'trend': 'up', 'change': 0.05, 'history': [0.5, 0.55, 0.6]},
                    'accuracyScore': {'value': 0.92, 'trend': 'up', 'change': 0.01, 'history': [0.9, 0.91, 0.92]},
                    'innovationIndex': {'value': 0.5, 'trend': 'stable', 'change': 0, 'history': [0.5, 0.5, 0.5]},
                },
                'efficiency': {
                    'tokenEfficiency': {'value': 0.8, 'trend': 'up', 'change': 0.03, 'history': [0.75, 0.78, 0.8]},
                    'computeUtilization': {'value': 0.65, 'trend': 'down', 'change': -0.02, 'history': [0.7, 0.68, 0.65]},
                },
                'usage': {
                    'requestsPerMinute': {'value': 5, 'trend': 'up', 'change': 1, 'history': [3, 4, 5]},
                    'activeUsers': {'value': 1, 'trend': 'stable', 'change': 0, 'history': [1, 1, 1]},
                }
            }
        elif method == 'get_api_keys':
            # Return empty API keys structure
            result = {
                'openai': '',
                'anthropic': '',
                'deepseek': '',
                'ollama': ''
            }
        elif method == 'test_api_key':
            # Very basic validation stub
            result = { 'valid': True, 'message': 'Key format accepted (stub)' }
        elif method == 'reset_settings_to_defaults':
            result = {'success': True, 'message': 'Settings reset to defaults (stub)'}
        elif method == 'generate_question':
            cfg = args[0] if (args and isinstance(args[0], dict)) else {
                'topic': args[0] if len(args) > 0 else 'General',
                'difficulty': args[1] if len(args) > 1 else 'medium',
                'numQuestions': 1
            }
            quiz = handle_generate_quiz({ **cfg, 'numQuestions': 1 })
            # Return a single question
            result = quiz.get('questions', [{}])[0]
        elif method == 'test_deepseek_pipeline':
            result = { 'status': 'ok', 'message': 'Pipeline test executed (stub)' }
        elif method == 'process_document_for_deepseek':
            # Start a fake processing and emit progress/completion events
            doc_cfg = args[0] if (args and isinstance(args[0], dict)) else {}
            doc_id = doc_cfg.get('document_id', f'doc_{int(time.time())}')
            try:
                socketio.emit('deepseek_document_progress', {
                    'document_id': doc_id,
                    'stage': 'parsing',
                    'progress': 50
                })
                time.sleep(0.2)
                socketio.emit('deepseek_document_complete', {
                    'document_id': doc_id,
                    'concepts': ['Concept A', 'Concept B', 'Concept C'],
                    'complexity': 7,
                    'readability': 65
                })
            except Exception as _e:
                logger.warning(f"DeepSeek document event emit failed: {_e}")
            result = { 'document_id': doc_id, 'status': 'processing_started' }
        elif method == 'get_history_stats':
            # Provide simple summary stats for BridgeTest
            result = {
                'totalQuestions': 42,
                'topics': ['General Knowledge'],
                'difficultyBreakdown': { 'easy': 10, 'medium': 20, 'hard': 12 }
            }
        elif method == 'logClientError':
            # Log and ack client-side error reports
            try:
                payload = args[0] if (args and isinstance(args[0], dict)) else {'message': 'unknown'}
                logger.error(f"CLIENT_ERROR: {payload}")
            except Exception:
                pass
            result = {'logged': True}
        else:
            return jsonify({
                'status': 'error',
                'message': f'Unknown method: {method}',
                'id': request_id
            }), 400
        
        return jsonify({
            'status': 'success',
            'data': result,
            'id': request_id
        })
        
    except Exception as e:
        logger.error(f"‚ùå API call failed: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e),
            'id': data.get('id') if 'data' in locals() else None
        }), 500

@app.route('/api/generate-quiz', methods=['POST'])
def generate_quiz_route():
    """REST convenience endpoint used by the Next.js UI to generate a quiz"""
    try:
        cfg = request.get_json() or {}
        result = handle_generate_quiz(cfg)
        return jsonify({ 'status': 'success', 'data': result })
    except Exception as e:
        logger.error(f"‚ùå /api/generate-quiz failed: {e}")
        return jsonify({ 'status': 'error', 'message': str(e) }), 500

@app.route('/api/train-model', methods=['POST'])
def train_model_route():
    """REST convenience endpoint used by the Next.js UI to start training"""
    try:
        cfg = request.get_json() or {}
        result = handle_start_training(cfg)
        return jsonify({ 'status': 'success', 'data': result })
    except Exception as e:
        logger.error(f"‚ùå /api/train-model failed: {e}")
        return jsonify({ 'status': 'error', 'message': str(e) }), 500

@app.route('/api/adapt-ui', methods=['POST'])
def adapt_ui_route():
    """Provide simple UI suggestions based on topic (used by quiz-generation page)"""
    try:
        data = request.get_json() or {}
        topic = data.get('topic', 'General')
        suggestions = {
            'prompt_enhancements': [
                f"Focus on core principles of {topic}",
                f"Include real-world examples of {topic}",
                f"Ask about common misconceptions in {topic}"
            ],
            'suggested_topics': [
                f"Introduction to {topic}",
                f"Advanced {topic}",
                f"Applications of {topic}"
            ]
        }
        return jsonify({ 'status': 'success', 'suggestions': suggestions })
    except Exception as e:
        logger.error(f"‚ùå /api/adapt-ui failed: {e}")
        return jsonify({ 'status': 'error', 'message': str(e) }), 500

# WebSocket: basic MCQ streaming stub for UI compatibility
@socketio.on('start-streaming-mcq')
def handle_start_streaming_mcq(config):
    try:
        topic = (config or {}).get('topic', 'General Knowledge')
        # Emit a few token events to simulate streaming
        tokens = [
            f"Generating question about {topic}... ",
            "Analyzing concepts... ",
            "Formulating options... "
        ]
        for t in tokens:
            emit('mcq-stream', { 'type': 'token', 'data': t })
            time.sleep(0.3)
        emit('mcq-stream', { 'type': 'question_end' })
        emit('mcq-stream', { 'type': 'stream_end' })
    except Exception as e:
        logger.error(f"‚ùå Streaming error: {e}")

def handle_generate_quiz(config: Dict[str, Any]) -> Dict[str, Any]:
    """Generate a quiz using the existing MCQ system"""
    try:
        topic = config.get('topic', 'General Knowledge')
        difficulty = config.get('difficulty', 'medium')
        num_questions = config.get('numQuestions', 2)
        question_type = config.get('questionType', 'mixed')
        mode = config.get('mode', 'auto')
        enable_token_streaming = config.get('tokenStreamingEnabled', False)
        
        logger.info(f"üß† Generating quiz: {topic}, {difficulty}, {num_questions} questions")
        
        # Use your existing MCQ generation logic if available
        if mcq_manager:
            try:
                # Call the actual generate_quiz method with correct parameters
                raw_questions = mcq_manager.generate_quiz(
                    topic=topic,
                    difficulty=difficulty,
                    num_questions=num_questions,
                    mode=mode,
                    submode=question_type,  # submode maps to question_type
                    question_type=question_type,
                    enable_token_streaming=enable_token_streaming,
                    deepseek_model=None,  # Will be set based on difficulty
                    custom_prompt=""  # Empty for now
                )
                
                logger.info(f"‚úÖ Generated {len(raw_questions)} questions using MCQ Manager")
                
                # Convert to Next.js format
                questions = []
                for i, question_data in enumerate(raw_questions):
                    if isinstance(question_data, dict):
                        # Handle the format from your MCQ manager
                        formatted_question = {
                            'id': question_data.get('id', f'q_{i}_{int(time.time())}'),
                            'text': question_data.get('question', question_data.get('text', f'Generated question {i+1} about {topic}?')),
                            'options': [],
                            'correctAnswerId': '',
                            'explanation': question_data.get('explanation', 'This is the explanation for the question.')
                        }
                        
                        # Handle options - could be list of strings or list of dicts
                        options = question_data.get('options', ['Option A', 'Option B', 'Option C', 'Option D'])
                        if isinstance(options, list):
                            for j, option in enumerate(options):
                                if isinstance(option, str):
                                    formatted_question['options'].append({
                                        'id': f'opt_{i}_{j}',
                                        'text': option
                                    })
                                elif isinstance(option, dict):
                                    formatted_question['options'].append({
                                        'id': option.get('id', f'opt_{i}_{j}'),
                                        'text': option.get('text', f'Option {chr(65+j)}')
                                    })
                        
                        # Set correct answer
                        correct_index = question_data.get('correct', question_data.get('correctAnswerId', 0))
                        if isinstance(correct_index, int) and correct_index < len(formatted_question['options']):
                            formatted_question['correctAnswerId'] = formatted_question['options'][correct_index]['id']
                        elif isinstance(correct_index, str):
                            formatted_question['correctAnswerId'] = correct_index
                        
                        questions.append(formatted_question)
                    else:
                        # Fallback for unexpected format
                        questions.append({
                            'id': f'q_{i}_{int(time.time())}',
                            'text': f'Generated question {i+1} about {topic}?',
                            'options': [
                                {'id': f'opt_{i}_0', 'text': 'Option A'},
                                {'id': f'opt_{i}_1', 'text': 'Option B'},
                                {'id': f'opt_{i}_2', 'text': 'Option C'},
                                {'id': f'opt_{i}_3', 'text': 'Option D'},
                            ],
                            'correctAnswerId': f'opt_{i}_0',
                            'explanation': 'This is a generated explanation.'
                        })
                
                quiz_data = {
                    'id': f'quiz_{int(time.time())}',
                    'totalQuestions': len(questions),
                    'questions': questions
                }
                
                logger.info(f"‚úÖ Quiz formatted successfully with {len(questions)} questions")
                return quiz_data
                
            except Exception as e:
                logger.error(f"‚ùå MCQ Manager failed: {e}")
                # Fall through to fallback
        
        # Fallback quiz if MCQ manager not available or failed
        questions = []
        for i in range(num_questions):
            questions.append({
                'id': f'q_{i}_{int(time.time())}',
                'text': f'Demo question {i+1}: What is a key concept in {topic}?',
                'options': [
                    {'id': f'opt_{i}_0', 'text': f'Correct answer about {topic}'},
                    {'id': f'opt_{i}_1', 'text': f'Incorrect option B'},
                    {'id': f'opt_{i}_2', 'text': f'Incorrect option C'},
                    {'id': f'opt_{i}_3', 'text': f'Incorrect option D'},
                ],
                'correctAnswerId': f'opt_{i}_0',
                'explanation': f'This is a demo explanation for the {topic} question.'
            })
        
        quiz_data = {
            'id': f'quiz_{int(time.time())}',
            'totalQuestions': len(questions),
            'questions': questions
        }
        
        logger.info(f"‚úÖ Fallback quiz generated with {len(questions)} questions")
        return quiz_data
        
    except Exception as e:
        logger.error(f"‚ùå Quiz generation failed: {e}")
        # Return minimal fallback quiz
        return {
            'id': f'quiz_{int(time.time())}',
            'totalQuestions': 1,
            'questions': [{
                'id': f'q_fallback_{int(time.time())}',
                'text': f'Fallback question about {config.get("topic", "General")}?',
                'options': [
                    {'id': 'opt_fallback_0', 'text': 'Option A'},
                    {'id': 'opt_fallback_1', 'text': 'Option B'},
                    {'id': 'opt_fallback_2', 'text': 'Option C'},
                    {'id': 'opt_fallback_3', 'text': 'Option D'},
                ],
                'correctAnswerId': 'opt_fallback_0',
                'explanation': 'This is a fallback question due to generation error.'
            }]
        }

def handle_get_question_history(filters: Dict[str, Any]) -> Dict[str, Any]:
    """Get question history from storage"""
    try:
        if question_history:
            history = question_history.get_question_history(
                limit=filters.get('limit', 50),
                offset=filters.get('offset', 0)
            )
            return {'questions': history}
        else:
            # Return mock data if history not available
            return {
                'questions': [
                    {
                        'id': f'q_{int(time.time())}',
                        'question': 'What is the capital of France?',
                        'options': ['London', 'Paris', 'Berlin', 'Madrid'],
                        'correct': 1,
                        'topic': 'Geography',
                        'difficulty': 'Easy',
                        'timestamp': '2025-01-08T12:00:00Z',
                        'explanation': 'Paris is the capital and largest city of France.'
                    }
                ]
            }
    except Exception as e:
        logger.error(f"‚ùå Failed to get question history: {e}")
        return {'questions': []}

def handle_submit_answer(question_id: str, answer: str) -> Dict[str, Any]:
    """Handle answer submission"""
    try:
        # Process answer submission logic here
        return {
            'correct': True,  # This would be calculated based on actual answer
            'explanation': 'Answer processed successfully'
        }
    except Exception as e:
        logger.error(f"‚ùå Failed to submit answer: {e}")
        return {'correct': False, 'explanation': 'Error processing answer'}

def handle_get_settings() -> Dict[str, Any]:
    """Get application settings"""
    try:
        # Return current settings with proper structure expected by SettingsPanel
        return {
            'defaultQuizConfig': {
                'topic': '',
                'mode': 'auto',
                'difficulty': 'medium',
                'numQuestions': 2
            },
            'providers': {
                'ollama': {
                    'enabled': True,
                    'status': 'üü¢',
                    'testing': False,
                    'apiKey': '',
                    'baseUrl': 'http://localhost:11434'
                },
                'openai': {
                    'enabled': False,
                    'status': 'üî¥',
                    'testing': False,
                    'apiKey': '',
                    'baseUrl': 'https://api.openai.com/v1'
                },
                'anthropic': {
                    'enabled': False,
                    'status': 'üî¥',
                    'testing': False,
                    'apiKey': '',
                    'baseUrl': 'https://api.anthropic.com'
                },
                'deepseek': {
                    'enabled': False,
                    'status': 'üî¥',
                    'testing': False,
                    'apiKey': '',
                    'baseUrl': 'https://api.deepseek.com'
                }
            },
            'userPreferences': {
                'darkMode': False,
                'defaultTimer': 30,
                'showAnswers': True,
                'saveQuestions': True
            },
            'modelPreferences': {
                'mcqModel': 'llama3.2:latest',
                'thinkingModel': 'deepseek-r1:14b',
                'selectionStrategy': 'auto'
            }
        }
    except Exception as e:
        logger.error(f"‚ùå Failed to get settings: {e}")
        return {
            'providers': {},
            'userPreferences': {
                'darkMode': False,
                'defaultTimer': 30,
                'showAnswers': True,
                'saveQuestions': True
            },
            'modelPreferences': {
                'mcqModel': 'llama3.2:latest',
                'thinkingModel': 'deepseek-r1:14b',
                'selectionStrategy': 'auto'
            }
        }

def handle_update_settings(settings: Dict[str, Any]) -> Dict[str, Any]:
    """Update application settings"""
    try:
        # Save settings logic here
        logger.info(f"üíæ Settings updated: {settings}")
        return {'success': True, 'message': 'Settings updated successfully'}
    except Exception as e:
        logger.error(f"‚ùå Failed to update settings: {e}")
        return {'success': False, 'message': str(e)}

def handle_get_deepseek_status() -> Dict[str, Any]:
    """Get DeepSeek pipeline status"""
    try:
        # Check if DeepSeek is available in your system
        return {
            'available': True,
            'ready': True,
            'thinking_model': 'deepseek-r1',
            'json_model': 'llama-3.1-8b'
        }
    except Exception as e:
        logger.error(f"‚ùå Failed to get DeepSeek status: {e}")
        return {'available': False, 'ready': False, 'error': str(e)}

def handle_start_training(config: Dict[str, Any]) -> Dict[str, Any]:
    """Start model training"""
    try:
        logger.info(f"üèãÔ∏è Starting training with config: {config}")
        # Training logic would go here
        return {
            'training_id': f'train_{int(time.time())}',
            'status': 'started',
            'message': 'Training started successfully'
        }
    except Exception as e:
        logger.error(f"‚ùå Failed to start training: {e}")
        return {'status': 'error', 'message': str(e)}

def handle_get_status() -> Dict[str, Any]:
    """Get system status"""
    try:
        return {
            'backend_status': 'running',
            'mcq_manager_ready': mcq_manager is not None,
            'question_history': question_history is not None,
            'ollama_inference': ollama_inference is not None
        }
    except Exception as e:
        logger.error(f"‚ùå Failed to get status: {e}")
        return {'backend_status': 'error', 'message': str(e)}

def handle_get_uploaded_files() -> str:
    """Get list of uploaded files"""
    try:
        # Check for uploaded files in the data directory
        upload_dir = Path("data/uploaded_books")
        if not upload_dir.exists():
            upload_dir.mkdir(parents=True, exist_ok=True)
        
        files = []
        for file_path in upload_dir.glob("*"):
            if file_path.is_file():
                files.append({
                    'name': file_path.name,
                    'size': file_path.stat().st_size,
                    'modified': file_path.stat().st_mtime
                })
        
        return json.dumps(files)
    except Exception as e:
        logger.error(f"‚ùå Failed to get uploaded files: {e}")
        return json.dumps([])

def handle_upload_file_base64(filename: str, base64_data: str) -> str:
    """Handle base64 file upload"""
    try:
        import base64
        
        # Decode base64 data
        file_data = base64.b64decode(base64_data)
        
        # Save to upload directory
        upload_dir = Path("data/uploaded_books")
        upload_dir.mkdir(parents=True, exist_ok=True)
        
        file_path = upload_dir / filename
        with open(file_path, 'wb') as f:
            f.write(file_data)
        
        logger.info(f"üìÅ File uploaded: {filename} ({len(file_data)} bytes)")
        return json.dumps({'success': True, 'message': f'File {filename} uploaded successfully'})
    except Exception as e:
        logger.error(f"‚ùå File upload failed: {e}")
        return json.dumps({'success': False, 'message': str(e)})

def handle_delete_uploaded_file(filename: str) -> str:
    """Delete an uploaded file"""
    try:
        upload_dir = Path("data/uploaded_books")
        file_path = upload_dir / filename
        
        if file_path.exists():
            file_path.unlink()
            logger.info(f"üóëÔ∏è File deleted: {filename}")
            return json.dumps({'success': True, 'message': f'File {filename} deleted successfully'})
        else:
            return json.dumps({'success': False, 'message': f'File {filename} not found'})
    except Exception as e:
        logger.error(f"‚ùå File deletion failed: {e}")
        return json.dumps({'success': False, 'message': str(e)})

def handle_get_training_config() -> str:
    """Get training configuration"""
    try:
        # Return default training config
        config = {
            'modelType': 'json',
            'epochs': 3,
            'batchSize': 5,
            'learningRate': 0.8,
            'adapterName': 'my_custom_model',
            'baseModel': 'llama3.2:latest',
            'trainingPreset': 'mixed'
        }
        return json.dumps(config)
    except Exception as e:
        logger.error(f"‚ùå Failed to get training config: {e}")
        return json.dumps({})

def handle_save_training_config(config: Dict[str, Any]) -> str:
    """Save training configuration"""
    try:
        # Save config logic here (could save to file or database)
        logger.info(f"üíæ Training config saved: {config}")
        return json.dumps({'success': True, 'message': 'Training configuration saved'})
    except Exception as e:
        logger.error(f"‚ùå Failed to save training config: {e}")
        return json.dumps({'success': False, 'message': str(e)})

def handle_get_available_models() -> str:
    """Get available models"""
    try:
        # Try to get models from Ollama first
        try:
            from urllib.request import urlopen, Request
            # urllib is in stdlib; avoid optional third-party deps
            req = Request('http://localhost:11434/api/tags', headers={'Accept': 'application/json'})
            with urlopen(req, timeout=5) as resp:
                status = getattr(resp, 'status', None) or resp.getcode()
                if status == 200:
                    data_bytes = resp.read()
                    ollama_data = json.loads(data_bytes.decode('utf-8'))
                    models = [m.get('name') for m in ollama_data.get('models', []) if isinstance(m, dict) and m.get('name')]
                    if models:
                        return json.dumps(models)
        except Exception:
            pass
        
        # Fallback to default models
        default_models = [
            'llama3.2:latest',
            'llama3.1:latest', 
            'phi3:latest',
            'mistral:latest',
            'qwen2.5:latest',
            'deepseek-coder:latest'
        ]
        return json.dumps(default_models)
    except Exception as e:
        logger.error(f"‚ùå Failed to get available models: {e}")
        return json.dumps([])

def handle_get_training_history() -> str:
    """Get training history"""
    try:
        # Return mock training history for now
        history = [
            {
                'runId': f'run_{int(time.time())}',
                'adapterName': 'my_custom_model',
                'baseModel': 'llama3.2:latest',
                'status': 'completed',
                'startTime': '2025-01-08T10:00:00Z',
                'endTime': '2025-01-08T10:30:00Z',
                'improvementScore': 85.5,
                'evaluationScore': 92.3
            }
        ]
        return json.dumps(history)
    except Exception as e:
        logger.error(f"‚ùå Failed to get training history: {e}")
        return json.dumps([])

def handle_stop_training() -> str:
    """Stop training"""
    try:
        # Stop training logic here
        logger.info("üõë Training stop requested")
        return json.dumps({'success': True, 'message': 'Training stopped'})
    except Exception as e:
        logger.error(f"‚ùå Failed to stop training: {e}")
        return json.dumps({'success': False, 'message': str(e)})

@app.route('/api/upload', methods=['POST'])
def upload_file():
    """Handle file uploads for training"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'No file provided'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'No file selected'}), 400
        
        # Save file and process
        filename = file.filename
        # File processing logic would go here
        
        logger.info(f"üìÅ File uploaded: {filename}")
        return jsonify({
            'success': True,
            'filename': filename,
            'message': 'File uploaded successfully'
        })
        
    except Exception as e:
        logger.error(f"‚ùå File upload failed: {e}")
        return jsonify({'error': str(e)}), 500

# WebSocket events for real-time communication
@socketio.on('connect')
def handle_connect():
    logger.info('üîå Client connected to WebSocket')
    emit('connection_status', {'connected': True})

@socketio.on('disconnect')
def handle_disconnect():
    logger.info('üîå Client disconnected from WebSocket')

if __name__ == '__main__':
    print("üöÄ Starting Next.js Bridge Server...")
    
    # Initialize backend components
    if initialize_backend():
        print("‚úÖ Backend initialized successfully")
    else:
        print("‚ö†Ô∏è Backend initialization failed, using fallback mode")
    
    print("üåê Server starting on http://localhost:8000")
    print("üì° WebSocket available for real-time communication")
    print("üîó CORS enabled for Next.js frontend")
    
    # Start the server
    socketio.run(app, host='0.0.0.0', port=8000, debug=True)
